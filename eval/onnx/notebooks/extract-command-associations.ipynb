{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/workdir/onnx-mlir-seeds/command_mapping.json\", \"r\") as f:\n",
    "    cmd_string_mapping = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gemm.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-onnx-to-stablehlo', '%s', '-split-input-file']),\n",
       " 'imperfectly_nested_stmts.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3', '--convert-krnl-to-affine', '%s', '-split-input-file']),\n",
       " 'Split_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Pad_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_shape_inference_optional.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '%s']),\n",
       " 'mul-2.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--convert-zhigh-to-onnx',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'relu-2.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--convert-zhigh-to-onnx',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'matmul-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'sub-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'GlobalPooling.mlir': ('onnx-mlir-opt',\n",
       "  ['--canonicalize',\n",
       "   '--convert-onnx-to-stablehlo',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Resize-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'pool.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Gather-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'Conv.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-tosa',\n",
       "   '-cse',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Elementwise-2.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'log.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Identity-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'krnl_global_elision.mlir': ('onnx-mlir-opt',\n",
       "  ['--elide-krnl-constants', '%s', '-split-input-file']),\n",
       " 'ScatterElements.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'onnx_constprop_no_shape_inference.mlir': ('onnx-mlir-opt',\n",
       "  ['--decompose-onnx', '--constprop-onnx', '%s', '-split-input-file']),\n",
       " 'common-rules.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Flatten.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-stablehlo',\n",
       "   '%s',\n",
       "   '--canonicalize',\n",
       "   '-split-input-file']),\n",
       " 'Shape.mlir': ('onnx-mlir-opt',\n",
       "  ['--canonicalize',\n",
       "   '--convert-onnx-to-stablehlo',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Conv_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'GatherElements-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'RamdomNormal.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'Pooling.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-onnx-to-stablehlo',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_decompose_convtranspose.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--decompose-onnx', '%s', '-split-input-file']),\n",
       " 'zhigh-combine.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'GatherND.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'onnx_hybrid_transform.mlir': ('onnx-mlir-opt',\n",
       "  ['-onnx-hybrid-transform=\"constant-propagation=false',\n",
       "   'decomposition=false\"',\n",
       "   '%s']),\n",
       " 'krnl_random_normal_lowering.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--convert-krnl-to-affine',\n",
       "   '--convert-krnl-to-llvm',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'GatherElements_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'meanreduce.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'meanreduce-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Sequence_with_dealloc.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--buffer-deallocation-pipeline',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Reduction_with_parallel_canonicalize_O3.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--march=x86-64',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl=enable-parallel',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'hoisting.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3', '--convert-krnl-to-affine', '%s', '-split-input-file']),\n",
       " 'krnl_region_lowering.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3', '--lower-krnl-region', '%s', '-split-input-file']),\n",
       " 'Slice_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'EntryPoint.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'Gather.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-onnx-to-stablehlo',\n",
       "   '%s',\n",
       "   '--canonicalize',\n",
       "   '-split-input-file']),\n",
       " 'onnx_simplify_shape_related_ops.mlir': ('onnx-mlir-opt',\n",
       "  ['--simplify-shape-related-ops-onnx', '%s', '-split-input-file']),\n",
       " 'gru-2.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Flatten-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'Softmax_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'krnl_substitution.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3', '--convert-krnl-to-affine', '%s']),\n",
       " 'If.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'ConvTranspose.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-stablehlo',\n",
       "   '--canonicalize',\n",
       "   '-split-input-file',\n",
       "   '%s']),\n",
       " 'MatMul_with_parallel_canonicalize_O3.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--march=x86-64',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl=enable-parallel',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Expand_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'matmul-3.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_conv_opt_conv_to_matmul.mlir': ('onnx-mlir-opt',\n",
       "  ['--conv-opt-onnx', '%s', '-split-input-file']),\n",
       " 'krnl_math_function_lowering.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--convert-krnl-to-affine',\n",
       "   '--convert-krnl-to-llvm',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'input_verification.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-krnl-to-llvm=\"verify-input-tensors=true\"',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_lowering_gru_op.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   \"--convert-onnx-to-krnl='emit-intermediate-ir'\",\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Resize.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-onnx-to-tosa', '-cse', '%s', '-split-input-file']),\n",
       " 'Loop_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'min.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'exp-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_lowering_range_op.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'lstm-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_cse.mlir': ('onnx-mlir-opt', ['--cse', '%s', '-split-input-file']),\n",
       " 'onnx_lowering_nonmaxsuppression_op.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'sub.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'div.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Unsqueeze-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'MatMul-1.mlir': ('onnx-mlir-opt',\n",
       "  ['-O0',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'MatMul_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'add-exec-cpu-opt.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '%s']),\n",
       " 'krnl_disconnect_dim_from_alloc.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3', '--lower-krnl-shape-to-std', '%s', '-split-input-file']),\n",
       " 'ShapeTransform_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'sigmoid.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'stick-unstick-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Pad.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-onnx-to-stablehlo',\n",
       "   '%s',\n",
       "   '--canonicalize',\n",
       "   '-split-input-file']),\n",
       " 'Transpose-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'krnl_to_affine.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3', '--convert-krnl-to-affine', '%s', '-split-input-file']),\n",
       " 'krnl_category_mapper.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--convert-krnl-to-affine',\n",
       "   '--convert-krnl-to-llvm',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx-on-ztensor.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'conv-2.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Normalization_O3_SIMD_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--mtriple=s390x-ibm-loz',\n",
       "   '--mcpu=z16',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_lowering_rnn_op.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--shape-inference',\n",
       "   \"--convert-onnx-to-krnl='emit-intermediate-ir'\",\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'device_placement_pass.mlir': ('onnx-mlir-opt',\n",
       "  ['--device-placement',\n",
       "   '--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--split-input-file',\n",
       "   '%s']),\n",
       " 'onnx_shape_inference_maxpool.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '%s', '-split-input-file']),\n",
       " 'onnx_constprop_flags.mlir': ('onnx-mlir-opt',\n",
       "  ['--constprop-onnx',\n",
       "   '--onnx-const-prop-expansion-bound=2',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'MatMulInteger_with_canonicalize_O3.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--mtriple=s390x-ibm-loz',\n",
       "   '--mcpu=z16',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'dyn-dim-analysis.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--onnx-dim-analysis',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'fold-std-alloc.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--fold-std-alloc',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'mul.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'unroll.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3', '--convert-krnl-to-affine', '%s', '-split-input-file']),\n",
       " 'SequenceErase.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'MatMul.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-stablehlo',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Softmax_with_parallel_canonicalize_O3.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--march=x86-64',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl=enable-parallel',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'conv-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'add-3.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--convert-zhigh-to-onnx',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'krnl_getref_lowering.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--convert-krnl-to-affine',\n",
       "   '--convert-krnl-to-llvm',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'lower-all-to-llvm-constant-shape.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--convert-krnl-to-llvm',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'DynamicQuantizeLinear_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_decompose.mlir': ('onnx-mlir-opt',\n",
       "  ['--decompose-onnx', '%s', '-split-input-file']),\n",
       " 'QuantizeLinear_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'MaxPoolSingleOut.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-tosa',\n",
       "   '-cse',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'stickified-constant-of-shape.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'TopK_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'reshape.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--convert-krnl-to-affine',\n",
       "   '--convert-krnl-to-llvm',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Softmax.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-tosa', '%s', '-split-input-file']),\n",
       " 'Split-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'krnl_normalization.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3', '--normalize-memrefs', '%s', '-split-input-file']),\n",
       " 'tanh.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'AveragePool.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-tosa',\n",
       "   '-cse',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'f32_to_dlf16.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Normalization_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'lstm.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '--zlow-rewrite',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'lrodata-section.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--convert-krnl-to-llvm=\"use-lrodata-section=true\"',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Pooling-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'exp.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'lstm-2.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'constants-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-krnl-to-llvm=\"store-constants-to-file',\n",
       "   'constants-to-file-single-threshold=0.03',\n",
       "   'constants-to-file-total-threshold=0.00000006\"',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'conv.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Constant-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-onnx-to-stablehlo', '%s', '-split-input-file']),\n",
       " 'max-2.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--convert-zhigh-to-onnx',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_shape_inference.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '%s', '-split-input-file']),\n",
       " 'HardMax_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'constprop.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--constprop-zhigh',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_constprop.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--constprop-onnx', '%s', '-split-input-file']),\n",
       " 'zhigh-layout-propagation.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--zhigh-layout-prop',\n",
       "   '--shape-inference',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'matmul-2.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_decompose_customop.mlir': ('onnx-mlir-opt',\n",
       "  ['--decompose-onnx', '%s', '-split-input-file']),\n",
       " 'entry_point.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-krnl-to-llvm', '--canonicalize', '%s', '-split-input-file']),\n",
       " 'min-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'pool-2.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'ConstantOfShape.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'Reduction-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'onnx_shape_inference_einsum.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '%s', '-split-input-file']),\n",
       " 'Squeeze.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-stablehlo',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Pooling_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Clip.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-onnx-to-stablehlo',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'buffer_copy.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--convert-krnl-to-affine',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Concat_with_parallel_canonicalize_O3.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--march=x86-64',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl=enable-parallel',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'krnl_global_with_alignment_lowering.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3', '--convert-krnl-to-llvm', '%s', '-split-input-file']),\n",
       " 'Tile_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'mul-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'DequantizeLinear_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Conv-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-stablehlo',\n",
       "   '%s',\n",
       "   '--canonicalize',\n",
       "   '-split-input-file']),\n",
       " 'Squeeze-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'Transpose.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-stablehlo',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'block.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3', '--convert-krnl-to-affine', '%s', '-split-input-file']),\n",
       " 'Transpose_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'LayoutTransform_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_fold.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--canonicalize', '%s', '-split-input-file']),\n",
       " 'stick-unstick.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Normalization-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'onnx_lowering_lstm_op.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--shape-inference',\n",
       "   \"--convert-onnx-to-krnl='emit-intermediate-ir'\",\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'gemm.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'max.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'tanh-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'ops.mlir': ('onnx-mlir-opt', ['%s', '-mlir-print-op-generic']),\n",
       " 'krnl_C_library_function_lowering.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--convert-krnl-to-affine',\n",
       "   '--convert-krnl-to-llvm',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Trilu_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'constants_mix_types.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-krnl-to-llvm=\"store-constants-to-file',\n",
       "   'constants-to-file-single-threshold=0.03',\n",
       "   'constants-to-file-total-threshold=0.00000006\"',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file',\n",
       "   '&&',\n",
       "   'binary-decoder',\n",
       "   'model.constants.bin',\n",
       "   '-s',\n",
       "   '0',\n",
       "   '-n',\n",
       "   '40',\n",
       "   '--onnx::TensorProto::FLOAT',\n",
       "   '-rm']),\n",
       " 'gru-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'sigmoid-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Identity.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-stablehlo',\n",
       "   '%s',\n",
       "   '--canonicalize',\n",
       "   '-split-input-file']),\n",
       " 'Reshape-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-stablehlo',\n",
       "   '--canonicalize',\n",
       "   '--cse',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'log-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Concat.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-onnx-to-stablehlo', '%s', '-split-input-file']),\n",
       " 'ArgMax.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-stablehlo',\n",
       "   '%s',\n",
       "   '--canonicalize',\n",
       "   '-split-input-file']),\n",
       " 'RamdomNormalLike.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'Reduction_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'ReduceMean.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-tosa',\n",
       "   '-cse',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'zlow-rewrite.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--zlow-rewrite',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'krnl_to_affine_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--convert-krnl-to-affine',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'ReverseSquence.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'Split.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-stablehlo',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_canonicalization.mlir': ('onnx-mlir-opt',\n",
       "  ['--canonicalize', '%s', '-split-input-file']),\n",
       " 'relu.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_structure.mlir': ('onnx-mlir-opt', ['%s', '-split-input-file']),\n",
       " 'sub-2.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--convert-zhigh-to-onnx',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Elementwise_with_parallel_canonicalize_O3.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--march=x86-64',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl=enable-parallel',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'relu-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Reduction_with_canonicalize_O3.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--mtriple=s390x-ibm-loz',\n",
       "   '--mcpu=z16',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_lowering_depth_to_space_op.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--shape-inference',\n",
       "   \"--convert-onnx-to-krnl='emit-intermediate-ir'\",\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Custom_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'rewrite-onnx-for-zhigh.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--rewrite-onnx-for-zhigh',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'krnl_memset.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-krnl-to-affine',\n",
       "   '--normalize-memrefs',\n",
       "   '--convert-krnl-to-affine',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Reshape_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'If_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'min-2.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--convert-zhigh-to-onnx',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'zhigh-clip-to-dlfloat-range.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--zhigh-clip-to-dlfloat',\n",
       "   '-split-input-file',\n",
       "   '%s']),\n",
       " 'Constant.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-tosa', '%s', '-split-input-file']),\n",
       " 'Tile.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-stablehlo',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Size.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'get_induction_var_value.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3', '--convert-krnl-to-affine', '%s', '-split-input-file']),\n",
       " 'constants.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-krnl-to-llvm=\"store-constants-to-file',\n",
       "   'constants-to-file-single-threshold=0.03',\n",
       "   'constants-to-file-total-threshold=0.00000006\"',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_dim_analysis.mlir': ('onnx-mlir-opt',\n",
       "  ['--onnx-dim-analysis', '%s', '-split-input-file']),\n",
       " 'krnl_shape_lowering.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3', '--lower-krnl-shape', '%s', '-split-input-file']),\n",
       " 'Gemm_to_matmul.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-tosa', '%s', '-split-input-file']),\n",
       " 'normalize-memref.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--normalize-memrefs',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Elementwise-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-onnx-to-stablehlo',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Reshape.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-tosa', '%s', '-split-input-file']),\n",
       " 'SequenceInsert_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'test-datalayout.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'softmax-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_decompose_einsum.mlir': ('onnx-mlir-opt',\n",
       "  ['--decompose-onnx', '%s', '-split-input-file']),\n",
       " 'symbol-postfix.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-krnl-to-llvm', '--canonicalize', '%s', '-split-input-file']),\n",
       " 'Gemm_to_linear.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-tosa', '%s', '-split-input-file']),\n",
       " 'gru.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_conv_opt.mlir': ('onnx-mlir-opt',\n",
       "  [\"--conv-opt-onnx='simd-data-layout'\", '%s', '-split-input-file']),\n",
       " 'Elementwise_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Transpose_with_parallel_canonicalize_O3.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--march=x86-64',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl=enable-parallel',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Normalization.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-onnx-to-stablehlo', '%s', '-split-input-file']),\n",
       " 'add-2.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'elementwise.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Expand.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-stablehlo',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Unique_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Softmax-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--decompose-onnx=\"target=stablehlo\"',\n",
       "   '--convert-onnx-to-stablehlo',\n",
       "   '%s',\n",
       "   '--canonicalize',\n",
       "   '-split-input-file']),\n",
       " 'Gemm_with_parallel_canonicalize_O3.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--march=x86-64',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl=enable-parallel',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'lower-all-to-llvm.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--convert-krnl-to-llvm',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'softmax.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'krnl_to_llvm_omtensor_ownership.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--convert-krnl-to-llvm',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'GatherElements.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-onnx-to-stablehlo',\n",
       "   '%s',\n",
       "   '--canonicalize',\n",
       "   '-split-input-file']),\n",
       " 'dlf16_to_f32.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'CumSum_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_lowering_fuse.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Squeeze_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Gemm_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'sum.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'krnl_sequence_lowering.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3', '--convert-seq-to-memref', '%s', '-split-input-file']),\n",
       " 'Constant-2.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'Compress_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Gather_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'div-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Concat_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_lowering_call_canonicalize_O3.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--mtriple=s390x-ibm-loz',\n",
       "   '--mcpu=z16',\n",
       "   '--shape-inference',\n",
       "   \"--convert-onnx-to-krnl='ops-for-call=Conv'\",\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_recompose.mlir': ('onnx-mlir-opt',\n",
       "  ['--recompose-onnx', '--canonicalize', '%s', '-split-input-file']),\n",
       " 'Loop.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'device_placement_pass_perf_model.mlir': ('onnx-mlir-opt',\n",
       "  ['--device-placement=use-faster=true',\n",
       "   '--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--split-input-file',\n",
       "   '%s']),\n",
       " 'MatMulInteger_with_canonicalize.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'lower-all-to-llvm-typed-pointer.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--convert-krnl-to-llvm',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_set_node_name.mlir': ('onnx-mlir-opt',\n",
       "  ['--set-onnx-node-name', '--split-input-file', '%s']),\n",
       " 'add-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'permute.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3', '--convert-krnl-to-affine', '%s', '-split-input-file']),\n",
       " 'pool-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'ScatterND.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'zhigh-decompose-stick-unstick.mlir': ('onnx-mlir-opt',\n",
       "  ['-mcpu=z16',\n",
       "   '-maccel=NNPA',\n",
       "   '--zhigh-decompose-stick-unstick',\n",
       "   '--split-input-file',\n",
       "   '%s']),\n",
       " 'max-1.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'reducemean.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-zhigh',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_lowering_space_to_depth.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--shape-inference',\n",
       "   \"--convert-onnx-to-krnl='emit-intermediate-ir'\",\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Reshape-2.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference', '--convert-onnx-to-krnl', '%s', '-split-input-file']),\n",
       " 'Elementwise.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-tosa',\n",
       "   '-cse',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Unsqueeze.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-stablehlo',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Slice.mlir': ('onnx-mlir-opt',\n",
       "  ['--shape-inference',\n",
       "   '--convert-onnx-to-stablehlo',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'onnx_lowering_category_mapper.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'stickified-constant.mlir': ('onnx-mlir-opt',\n",
       "  ['--mcpu=z16',\n",
       "   '--maccel=NNPA',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'Reduction.mlir': ('onnx-mlir-opt',\n",
       "  ['--convert-onnx-to-stablehlo',\n",
       "   '%s',\n",
       "   '--canonicalize',\n",
       "   '-split-input-file']),\n",
       " 'Elementwise_with_canonicalize_O3.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--mtriple=s390x-ibm-loz',\n",
       "   '--mcpu=z16',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file']),\n",
       " 'MatMul_with_canonicalize_O3.mlir': ('onnx-mlir-opt',\n",
       "  ['-O3',\n",
       "   '--mtriple=s390x-ibm-loz',\n",
       "   '--mcpu=z16',\n",
       "   '--shape-inference',\n",
       "   '--convert-onnx-to-krnl',\n",
       "   '--canonicalize',\n",
       "   '%s',\n",
       "   '-split-input-file'])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_cmd(text):\n",
    "    # for now let's only consider mlir-opt\n",
    "    pattern = r\"^(onnx-mlir-opt) (.*?)[|\\n]\"\n",
    "    matches = re.findall(pattern, text)\n",
    "    if len(matches) < 1:\n",
    "        return None\n",
    "    if len(matches) > 1:\n",
    "        #print(text)\n",
    "        #raise ValueError(\"Expected at most one match\")\n",
    "        return None\n",
    "    command, args = matches[0]\n",
    "    return command, args.split()\n",
    "\n",
    "cmd_mapping = dict()\n",
    "for filename, command_strings in cmd_string_mapping.items():\n",
    "    # concatenate command strings\n",
    "    full_string = \"\"\n",
    "    for cmd_str in command_strings:\n",
    "        matches = re.findall(r\"//\\s+RUN:\\s+(\\S.*)\", cmd_str)\n",
    "        if len(matches) < 1:\n",
    "            break\n",
    "        if len(matches) > 1:\n",
    "            raise ValueError(\"Expected at most one match\")\n",
    "        full_string += matches[0]\n",
    "    full_string = full_string.replace(\"\\\\\", \"\")\n",
    "    #if \"mlir-opt\" in full_string:\n",
    "    #    print(full_string)\n",
    "    #    print(\"----\")\n",
    "    try:\n",
    "        cmd_mapping[filename] = get_cmd(full_string)\n",
    "    except:\n",
    "        print(filename)\n",
    "\n",
    "# filter out non mlir-opt commands\n",
    "cmd_mapping = {file: cmdargs for file, cmdargs in cmd_mapping.items() if cmdargs is not None}\n",
    "cmd_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialects = [\n",
    "   \"onnx\", \"krnl\", \"zhigh\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect_associations = dict()\n",
    "for cmd, args in cmd_mapping.values():\n",
    "    for arg in args:\n",
    "        possible_match = re.match(r\"--?convert-([a-z]+)-to\", arg)\n",
    "        if possible_match:\n",
    "            dialect = possible_match.group(1)\n",
    "            if dialect not in dialect_associations:\n",
    "                dialect_associations[dialect] = []\n",
    "            if arg not in dialect_associations[dialect]:\n",
    "                dialect_associations[dialect].append(arg)\n",
    "        possible_match = re.match(r\"--?([a-z]+)\", arg)\n",
    "        if possible_match:\n",
    "            dialect = possible_match.group(1)\n",
    "            if dialect in dialects:\n",
    "                if dialect not in dialect_associations:\n",
    "                    dialect_associations[dialect] = []\n",
    "                if arg not in dialect_associations[dialect]:\n",
    "                    dialect_associations[dialect].append(arg)\n",
    "with open(\"/workdir/mlir-eval/onnx/dialect-associations.json\", \"w\") as f:\n",
    "    json.dump(dialect_associations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthfuzz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
